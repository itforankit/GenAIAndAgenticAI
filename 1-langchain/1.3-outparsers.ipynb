{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ebc437c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c71f9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "## Langsmith Tracking and tracing\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40cd7dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\AIandGenAI_Krish_May25\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3667: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "#OpenAI Tools\n",
    "#These output parsers extract tool calls from OpenAI's function calling API responses. This means they are only usable with models that support function calling, \n",
    "# and specifically the latest tools and tool_choice parameters.\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61fed55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1395841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0).bind_tools([Joke])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c1ddb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'Joke',\n",
       "   'description': 'Joke to tell user.',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'setup': {'description': 'question to set up a joke',\n",
       "      'type': 'string'},\n",
       "     'punchline': {'description': 'answer to resolve the joke',\n",
       "      'type': 'string'}},\n",
       "    'required': ['setup', 'punchline']}}}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.kwargs[\"tools\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b808190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"You are helpful assistant\"), (\"user\", \"{input}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ace18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_tools import JsonOutputToolsParser\n",
    "parser = JsonOutputToolsParser()\n",
    "#we can also user Key_name\n",
    "#parser = JsonOutputKeyToolsParser(key_name=\"Joke\")\n",
    "\n",
    "#Certain models can return multiple tool invocations each call, so by default the output is a list. If we just want to return the first tool invocation, we can specify first_tool_only=True\n",
    "#parser = JsonOutputKeyToolsParser(key_name=\"Joke\", first_tool_only=True)\n",
    "chain = prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b1bdd13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'args': {'setup': \"Why couldn't the bicycle stand up by itself?\",\n",
       "   'punchline': 'Because it was two tired!'},\n",
       "  'type': 'Joke'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"tell me a joke\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72242f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PydanticToolsParser\n",
    "#This builds on top of JsonOutputToolsParser but passes the results to a Pydantic Model. This allows for further validation should you choose.\n",
    "from langchain.output_parsers.openai_tools import PydanticToolsParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b6ed37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "    # You can add custom validation logic easily with Pydantic.\n",
    "    @validator(\"setup\")\n",
    "    def question_ends_with_question_mark(cls, field):\n",
    "        if field[-1] != \"?\":\n",
    "            raise ValueError(\"Badly formed question!\")\n",
    "        return field\n",
    "\n",
    "\n",
    "parser = PydanticToolsParser(tools=[Joke])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24c4ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0).bind_tools([Joke])\n",
    "chain = prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ca545b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Joke(setup=\"Why couldn't the bicycle stand up by itself?\", punchline='Because it was two tired!')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"tell me a joke\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558e4d5e",
   "metadata": {},
   "source": [
    "Pandas DataFrame Parser\n",
    "\n",
    "A Pandas DataFrame is a popular data structure in the Python programming language, commonly used for data manipulation and analysis. It provides a comprehensive set of tools for working with structured data, making it a versatile option for tasks such as data cleaning, transformation, and analysis.\n",
    "\n",
    "This output parser allows users to specify an arbitrary Pandas DataFrame and query LLMs for data in the form of a formatted dictionary that extracts data from the corresponding DataFrame. Keep in mind that large language models are leaky abstractions! You'll have to use an LLM with sufficient capacity to generate a well-formed query as per the defined format instructions.\n",
    "\n",
    "Use Pandas' DataFrame object to declare the DataFrame you wish to perform queries on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "337d9835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from typing import Any, Dict\n",
    "\n",
    "import pandas as pd\n",
    "from langchain.output_parsers import PandasDataFrameOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06146cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fae86469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solely for documentation purposes.\n",
    "def format_parser_output(parser_output: Dict[str, Any]) -> None:\n",
    "    for key in parser_output.keys():\n",
    "        parser_output[key] = parser_output[key].to_dict()\n",
    "    return pprint.PrettyPrinter(width=4, compact=True).pprint(parser_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85113783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your desired Pandas DataFrame.\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"num_legs\": [2, 4, 8, 0],\n",
    "        \"num_wings\": [2, 0, 0, 0],\n",
    "        \"num_specimen_seen\": [10, 2, 1, 8],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PandasDataFrameOutputParser(dataframe=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f35015f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_wings': {0: 2,\n",
      "               1: 0,\n",
      "               2: 0,\n",
      "               3: 0}}\n"
     ]
    }
   ],
   "source": [
    "# Here's an example of a column operation being performed.\n",
    "df_query = \"Retrieve the num_wings column.\"\n",
    "\n",
    "# Set up the prompt.\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "parser_output = chain.invoke({\"query\": df_query})\n",
    "\n",
    "format_parser_output(parser_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8fd7573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'num_legs': 2,\n",
      "       'num_specimen_seen': 10,\n",
      "       'num_wings': 2}}\n"
     ]
    }
   ],
   "source": [
    "# Here's an example of a row operation being performed.\n",
    "df_query = \"Retrieve the first row.\"\n",
    "\n",
    "# Set up the prompt.\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "parser_output = chain.invoke({\"query\": df_query})\n",
    "\n",
    "format_parser_output(parser_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46656281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean': np.float64(4.0)}\n"
     ]
    }
   ],
   "source": [
    "# Here's an example of a random Pandas DataFrame operation limiting the number of rows\n",
    "df_query = \"Retrieve the average of the num_legs column from rows 1 to 3.\"\n",
    "\n",
    "# Set up the prompt.\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "parser_output = chain.invoke({\"query\": df_query})\n",
    "\n",
    "print(parser_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bbeb897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean': np.float64(3.5)}\n"
     ]
    }
   ],
   "source": [
    "# Here's an example of a poorly formatted query\n",
    "df_query = \"Retrieve the mean of the num_legs column.\"\n",
    "\n",
    "# Set up the prompt.\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "parser_output = chain.invoke({\"query\": df_query})\n",
    "print(parser_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb1977a",
   "metadata": {},
   "source": [
    "CSV parser\n",
    "This output parser can be used when you want to return a list of comma-separated items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a545791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "prompt = PromptTemplate(\n",
    "    template=\"List five {subject}.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(temperature=0)\n",
    "\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fe18200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Vanilla',\n",
       " 'Chocolate',\n",
       " 'Strawberry',\n",
       " 'Mint Chocolate Chip',\n",
       " 'Cookies and Cream']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"subject\": \"ice cream flavors\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039eebc4",
   "metadata": {},
   "source": [
    "XML parser\n",
    "This output parser allows users to obtain results from LLM in the popular XML format.\n",
    "\n",
    "Keep in mind that large language models are leaky abstractions! You'll have to use an LLM with sufficient capacity to generate well-formed XML.\n",
    "\n",
    "In the following example we use Claude model (https://docs.anthropic.com/claude/docs) which works really well with XML tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "101f4af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import XMLOutputParser\n",
    "from langchain_community.chat_models import ChatAnthropic\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c87f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the ANTHROPIC_API_KEY environment variable is set\n",
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "if not anthropic_api_key:\n",
    "\traise ValueError(\"ANTHROPIC_API_KEY environment variable is not set.\")\n",
    "\n",
    "# Initialize the ChatAnthropic model with the API key\n",
    "model = ChatAnthropic(model=\"claude-2\", max_tokens_to_sample=512, temperature=0.1, anthropic_api_key=anthropic_api_key)\n",
    "\n",
    "# Ensure that the model is used in a way that does not invoke unsupported methods\n",
    "# Avoid using components that require token counting or any unsupported features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c77d900",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_query = \"Generate the shortened filmography for Tom Hanks.\"\n",
    "output = model.invoke(\n",
    "    f\"\"\"{actor_query}\n",
    "Please enclose the movies in <movie></movie> tags\"\"\"\n",
    ")\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3435577",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = XMLOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"{query}\\n{format_instructions}\"\"\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "output = chain.invoke({\"query\": actor_query})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a067564",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = XMLOutputParser(tags=[\"movies\", \"actor\", \"film\", \"name\", \"genre\"])\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"{query}\\n{format_instructions}\"\"\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "output = chain.invoke({\"query\": actor_query})\n",
    "\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
